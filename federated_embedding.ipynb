{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[3852832567.py:29 <module>()] -> python d:\\installation\\conda\\envs\\py310\\lib\\site-packages\\ipykernel_launcher.py --f=c:\\Users\\A1495\\AppData\\Roaming\\jupyter\\runtime\\kernel-v3cd2a12560736939dcf70611eb1f4ae81621fa281.json\n",
      "[3852832567.py:30 <module>()] -> =================================\n",
      "[3852832567.py:31 <module>()] -> debug = True\n",
      "dumpfile_uniqueid = \n",
      "seed = 2000\n",
      "device = cuda:0\n",
      "root_dir = d:\\codes\\TrajMM\\fedtraj\n",
      "checkpoint_dir = d:\\codes\\TrajMM\\fedtraj/exp/snapshots\n",
      "dataset = porto\n",
      "dataset_prefix = porto_20200\n",
      "dataset_file = d:\\codes\\TrajMM\\fedtraj/data/porto_20200\n",
      "dataset_cell_file = d:\\codes\\TrajMM\\fedtraj/data/porto_20200_cell100_cellspace.pkl\n",
      "dataset_embs_file = d:\\codes\\TrajMM\\fedtraj/data/porto_20200_cell100_embdim32_embs.pkl\n",
      "method = fcl\n",
      "min_lon = -8.7005\n",
      "min_lat = 41.1001\n",
      "max_lon = -8.5192\n",
      "max_lat = 41.2086\n",
      "max_traj_len = 200\n",
      "min_traj_len = 5\n",
      "cell_size = 100\n",
      "cellspace_buffer = 50\n",
      "trajcl_batch_size = 128\n",
      "cell_embedding_dim = 32\n",
      "seq_embedding_dim = 32\n",
      "moco_proj_dim = 16\n",
      "moco_nqueue = 2048\n",
      "moco_temperature = 0.05\n",
      "test_type = distort\n",
      "trajcl_training_epochs = 20\n",
      "trajcl_training_bad_patience = 5\n",
      "trajcl_training_lr = 0.001\n",
      "trajcl_training_lr_degrade_gamma = 0.5\n",
      "trajcl_training_lr_degrade_step = 5\n",
      "trajcl_aug1 = mask\n",
      "trajcl_aug2 = splicing\n",
      "trajcl_local_mask_sidelen = 1100\n",
      "trans_attention_head = 4\n",
      "trans_attention_dropout = 0.1\n",
      "trans_attention_layer = 2\n",
      "trans_pos_encoder_dropout = 0.1\n",
      "trans_hidden_dim = 2048\n",
      "traj_simp_dist = 100\n",
      "traj_shift_dist = 200\n",
      "traj_mask_ratio = 0.3\n",
      "traj_add_ratio = 0.3\n",
      "traj_subset_ratio = 0.7\n",
      "test_exp1_lcss_edr_epsilon = 0.25\n",
      "trajsimi_encoder_name = TrajCL\n",
      "trajsimi_encoder_mode = finetune_all\n",
      "trajsimi_measure_fn_name = discret_frechet\n",
      "trajsimi_batch_size = 128\n",
      "trajsimi_epoch = 30\n",
      "trajsimi_training_bad_patience = 10\n",
      "trajsimi_learning_rate = 0.0001\n",
      "trajsimi_learning_weight_decay = 0.0001\n",
      "trajsimi_finetune_lr_rescale = 0.5\n",
      "cls_num = 5\n",
      "C = 1.0\n",
      "E = 1\n",
      "moon_loss_weight = 1.0\n",
      "fedproc_loss_weight = 0.0\n",
      "sigma = 0.01\n",
      "epsilon = 8\n",
      "bound = 0.001\n",
      "ldp = 0\n",
      "[3852832567.py:32 <module>()] -> =================================\n",
      "[data_loader.py:25 read_traj_dataset()] -> [Load traj dataset] START.\n",
      "[data_loader.py:42 read_traj_dataset()] -> [Load traj dataset] END. @=0, #=819(819/82/164)\n",
      "[utils.py:125 get_federated_segments()] -> [Split dataset and convert to segments] start converting\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\codes\\TrajMM\\fedtraj\\utils\\trajclus.py:19: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  projection = line[0] + (dot_product / line_length_squared) * line_vector\n",
      "163it [00:00, 577.12it/s]\n",
      "164it [00:00, 602.00it/s]\n",
      "164it [00:01, 148.82it/s]\n",
      "164it [00:00, 236.54it/s]\n",
      "164it [00:15, 10.66it/s]\n",
      "[utils.py:128 get_federated_segments()] -> [Split dataset and convert to segments] done\n",
      "164it [00:20,  7.84it/s]\n",
      "d:\\installation\\conda\\envs\\py310\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "d:\\installation\\conda\\envs\\py310\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "[fed_trainer.py:270 train()] -> [Training] START! timestamp=1740211154\n",
      "d:\\installation\\conda\\envs\\py310\\lib\\site-packages\\torch\\nn\\functional.py:5849: UserWarning: Support for mismatched src_key_padding_mask and mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client4 ep=0: avg_loss=5.889, gpu=(2109, 8188), ram=1228\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client1 ep=0: avg_loss=5.630, gpu=(2123, 8188), ram=1228\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client2 ep=0: avg_loss=6.129, gpu=(2125, 8188), ram=1228\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client3 ep=0: avg_loss=5.374, gpu=(2387, 8188), ram=1229\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client5 ep=0: avg_loss=6.082, gpu=(2639, 8188), ram=1230\n",
      "[fed_trainer.py:287 train()] -> [Training] ep=0: avg_loss=5.821, delta=0.000, @=28.508/28.510, time=28.510013103485107\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client1 ep=0: avg_loss=5.825, gpu=(2639, 8188), ram=1229\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client5 ep=0: avg_loss=5.746, gpu=(2799, 8188), ram=1229\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client3 ep=0: avg_loss=5.611, gpu=(2799, 8188), ram=1229\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client4 ep=0: avg_loss=5.773, gpu=(2799, 8188), ram=1229\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client2 ep=0: avg_loss=5.805, gpu=(2799, 8188), ram=1229\n",
      "[fed_trainer.py:287 train()] -> [Training] ep=1: avg_loss=5.752, delta=0.000, @=22.146/50.673, time=50.673048973083496\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client2 ep=0: avg_loss=5.408, gpu=(2799, 8188), ram=1230\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client3 ep=0: avg_loss=5.321, gpu=(2799, 8188), ram=1230\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client5 ep=0: avg_loss=5.405, gpu=(2799, 8188), ram=1229\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client4 ep=0: avg_loss=5.449, gpu=(2799, 8188), ram=1230\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client1 ep=0: avg_loss=5.504, gpu=(2799, 8188), ram=1229\n",
      "[fed_trainer.py:287 train()] -> [Training] ep=2: avg_loss=5.417, delta=0.000, @=22.342/73.032, time=73.0317952632904\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client5 ep=0: avg_loss=5.243, gpu=(2799, 8188), ram=1230\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client2 ep=0: avg_loss=5.138, gpu=(2799, 8188), ram=1230\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client4 ep=0: avg_loss=5.282, gpu=(2799, 8188), ram=1230\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client1 ep=0: avg_loss=5.234, gpu=(2799, 8188), ram=1229\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client3 ep=0: avg_loss=5.192, gpu=(2799, 8188), ram=1229\n",
      "[fed_trainer.py:287 train()] -> [Training] ep=3: avg_loss=5.218, delta=0.000, @=21.678/94.726, time=94.7258026599884\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client4 ep=0: avg_loss=5.145, gpu=(2799, 8188), ram=1230\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client3 ep=0: avg_loss=5.027, gpu=(2799, 8188), ram=1230\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client5 ep=0: avg_loss=5.106, gpu=(2799, 8188), ram=1231\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client1 ep=0: avg_loss=5.158, gpu=(2799, 8188), ram=1230\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client2 ep=0: avg_loss=5.077, gpu=(2799, 8188), ram=1229\n",
      "[fed_trainer.py:287 train()] -> [Training] ep=4: avg_loss=5.103, delta=0.000, @=22.095/116.838, time=116.83832430839539\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client4 ep=0: avg_loss=4.981, gpu=(2799, 8188), ram=1230\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client2 ep=0: avg_loss=4.898, gpu=(2799, 8188), ram=1230\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client3 ep=0: avg_loss=4.897, gpu=(2799, 8188), ram=1230\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client1 ep=0: avg_loss=4.984, gpu=(2799, 8188), ram=1230\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client5 ep=0: avg_loss=4.959, gpu=(2801, 8188), ram=1231\n",
      "[fed_trainer.py:287 train()] -> [Training] ep=5: avg_loss=4.944, delta=0.000, @=21.618/138.474, time=138.47411251068115\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client4 ep=0: avg_loss=4.930, gpu=(2801, 8188), ram=1230\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client1 ep=0: avg_loss=4.931, gpu=(2801, 8188), ram=1230\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client5 ep=0: avg_loss=4.944, gpu=(2801, 8188), ram=1229\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client3 ep=0: avg_loss=4.817, gpu=(2801, 8188), ram=1230\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client2 ep=0: avg_loss=4.797, gpu=(2801, 8188), ram=1230\n",
      "[fed_trainer.py:287 train()] -> [Training] ep=6: avg_loss=4.884, delta=0.000, @=22.201/160.689, time=160.68930387496948\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client5 ep=0: avg_loss=4.856, gpu=(2801, 8188), ram=1230\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client4 ep=0: avg_loss=4.859, gpu=(2799, 8188), ram=1230\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client1 ep=0: avg_loss=4.817, gpu=(2817, 8188), ram=1230\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client2 ep=0: avg_loss=4.778, gpu=(2817, 8188), ram=1230\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client3 ep=0: avg_loss=4.828, gpu=(2817, 8188), ram=1230\n",
      "[fed_trainer.py:287 train()] -> [Training] ep=7: avg_loss=4.828, delta=0.000, @=24.091/184.799, time=184.79877734184265\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client5 ep=0: avg_loss=4.761, gpu=(2817, 8188), ram=1230\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client2 ep=0: avg_loss=4.720, gpu=(2817, 8188), ram=1231\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client3 ep=0: avg_loss=4.696, gpu=(2817, 8188), ram=1230\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client1 ep=0: avg_loss=4.768, gpu=(2817, 8188), ram=1230\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client4 ep=0: avg_loss=4.761, gpu=(2831, 8188), ram=1230\n",
      "[fed_trainer.py:287 train()] -> [Training] ep=8: avg_loss=4.741, delta=0.000, @=23.674/208.491, time=208.49082899093628\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client4 ep=0: avg_loss=4.737, gpu=(2831, 8188), ram=1230\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client1 ep=0: avg_loss=4.725, gpu=(2831, 8188), ram=1230\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client2 ep=0: avg_loss=4.659, gpu=(2834, 8188), ram=1230\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client3 ep=0: avg_loss=4.693, gpu=(2834, 8188), ram=1230\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client5 ep=0: avg_loss=4.727, gpu=(2837, 8188), ram=1231\n",
      "[fed_trainer.py:287 train()] -> [Training] ep=9: avg_loss=4.708, delta=0.000, @=24.975/233.489, time=233.4889645576477\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client3 ep=0: avg_loss=4.567, gpu=(2853, 8188), ram=1230\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client2 ep=0: avg_loss=4.574, gpu=(2854, 8188), ram=1230\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client1 ep=0: avg_loss=4.676, gpu=(2821, 8188), ram=1230\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client5 ep=0: avg_loss=4.642, gpu=(2838, 8188), ram=1229\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client4 ep=0: avg_loss=4.649, gpu=(2854, 8188), ram=1230\n",
      "[fed_trainer.py:287 train()] -> [Training] ep=10: avg_loss=4.622, delta=0.000, @=25.864/259.374, time=259.3739688396454\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client5 ep=0: avg_loss=4.614, gpu=(2855, 8188), ram=1231\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client4 ep=0: avg_loss=4.603, gpu=(2871, 8188), ram=1230\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client1 ep=0: avg_loss=4.610, gpu=(2871, 8188), ram=1230\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client3 ep=0: avg_loss=4.478, gpu=(2871, 8188), ram=1231\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client2 ep=0: avg_loss=4.479, gpu=(2871, 8188), ram=1230\n",
      "[fed_trainer.py:287 train()] -> [Training] ep=11: avg_loss=4.557, delta=0.000, @=25.505/284.906, time=284.905885219574\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client4 ep=0: avg_loss=4.545, gpu=(2871, 8188), ram=1230\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client2 ep=0: avg_loss=4.499, gpu=(2871, 8188), ram=1230\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client5 ep=0: avg_loss=4.604, gpu=(2871, 8188), ram=1231\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client1 ep=0: avg_loss=4.525, gpu=(2883, 8188), ram=1230\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client3 ep=0: avg_loss=4.474, gpu=(2840, 8188), ram=1231\n",
      "[fed_trainer.py:287 train()] -> [Training] ep=12: avg_loss=4.529, delta=0.000, @=23.296/308.222, time=308.2219350337982\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client5 ep=0: avg_loss=4.520, gpu=(2847, 8188), ram=1230\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client2 ep=0: avg_loss=4.392, gpu=(2847, 8188), ram=1230\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client1 ep=0: avg_loss=4.541, gpu=(2863, 8188), ram=1230\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client3 ep=0: avg_loss=4.422, gpu=(2863, 8188), ram=1231\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client4 ep=0: avg_loss=4.530, gpu=(2848, 8188), ram=1230\n",
      "[fed_trainer.py:287 train()] -> [Training] ep=13: avg_loss=4.481, delta=0.000, @=25.267/333.505, time=333.50543427467346\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client1 ep=0: avg_loss=4.484, gpu=(2864, 8188), ram=1230\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client4 ep=0: avg_loss=4.482, gpu=(2848, 8188), ram=1230\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client3 ep=0: avg_loss=4.389, gpu=(2848, 8188), ram=1231\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client2 ep=0: avg_loss=4.398, gpu=(2848, 8188), ram=1231\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client5 ep=0: avg_loss=4.489, gpu=(2864, 8188), ram=1231\n",
      "[fed_trainer.py:287 train()] -> [Training] ep=14: avg_loss=4.448, delta=0.000, @=25.322/358.848, time=358.84763526916504\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client2 ep=0: avg_loss=4.338, gpu=(2848, 8188), ram=1231\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client5 ep=0: avg_loss=4.440, gpu=(2849, 8188), ram=1230\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client4 ep=0: avg_loss=4.498, gpu=(2848, 8188), ram=1230\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client3 ep=0: avg_loss=4.282, gpu=(2848, 8188), ram=1231\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client1 ep=0: avg_loss=4.420, gpu=(2849, 8188), ram=1231\n",
      "[fed_trainer.py:287 train()] -> [Training] ep=15: avg_loss=4.396, delta=0.000, @=25.692/384.558, time=384.55835461616516\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client3 ep=0: avg_loss=4.269, gpu=(2849, 8188), ram=1231\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client2 ep=0: avg_loss=4.258, gpu=(2849, 8188), ram=1231\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client5 ep=0: avg_loss=4.383, gpu=(2849, 8188), ram=1231\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client4 ep=0: avg_loss=4.377, gpu=(2866, 8188), ram=1230\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client1 ep=0: avg_loss=4.343, gpu=(2850, 8188), ram=1230\n",
      "[fed_trainer.py:287 train()] -> [Training] ep=16: avg_loss=4.326, delta=0.000, @=25.616/410.197, time=410.19680738449097\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client2 ep=0: avg_loss=4.294, gpu=(2858, 8188), ram=1230\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client3 ep=0: avg_loss=4.277, gpu=(2858, 8188), ram=1230\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client5 ep=0: avg_loss=4.369, gpu=(2862, 8188), ram=1231\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client1 ep=0: avg_loss=4.308, gpu=(2862, 8188), ram=1231\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client4 ep=0: avg_loss=4.380, gpu=(2866, 8188), ram=1230\n",
      "[fed_trainer.py:287 train()] -> [Training] ep=17: avg_loss=4.325, delta=0.000, @=24.878/435.094, time=435.09430956840515\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client2 ep=0: avg_loss=4.198, gpu=(2865, 8188), ram=1230\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client3 ep=0: avg_loss=4.265, gpu=(2865, 8188), ram=1231\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client4 ep=0: avg_loss=4.336, gpu=(2865, 8188), ram=1231\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client5 ep=0: avg_loss=4.342, gpu=(2865, 8188), ram=1231\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client1 ep=0: avg_loss=4.307, gpu=(2865, 8188), ram=1230\n",
      "[fed_trainer.py:287 train()] -> [Training] ep=18: avg_loss=4.290, delta=0.000, @=28.148/463.244, time=463.2436637878418\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client4 ep=0: avg_loss=4.299, gpu=(2905, 8188), ram=1230\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client3 ep=0: avg_loss=4.197, gpu=(2899, 8188), ram=1231\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client1 ep=0: avg_loss=4.302, gpu=(2867, 8188), ram=1231\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client2 ep=0: avg_loss=4.195, gpu=(2867, 8188), ram=1231\n",
      "[fed_trainer.py:168 local_train()] -> [Training] client5 ep=0: avg_loss=4.255, gpu=(2888, 8188), ram=1230\n",
      "[fed_trainer.py:287 train()] -> [Training] ep=19: avg_loss=4.249, delta=0.000, @=27.508/490.801, time=490.8010790348053\n",
      "[fed_trainer.py:311 train()] -> [Training] END! @=490.8253004550934, best_epoch=19, best_loss_train=4.249461\n",
      "[fed_trainer.py:331 test()] -> [Test]start.\n",
      "[fed_trainer.py:348 test()] -> [EXPFlag]task=newsimi,encoder=TrajCL,varying=distort,r1=1.000,r2=1.012,r3=1.006,r4=1.037,r5=1.000\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import logging\n",
    "import argparse\n",
    "\n",
    "from fedtraj.config import Config\n",
    "from fedtraj.utils import tool_funcs\n",
    "\n",
    "\n",
    "args = {\n",
    "    \"dataset\": \"porto\",\n",
    "    \"cell_size\": 100,\n",
    "    \"test_type\": \"distort\",\n",
    "    \"method\": \"fcl\",\n",
    "}\n",
    "\n",
    "Config.update(args)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG if Config.debug else logging.INFO,\n",
    "    format=\"[%(filename)s:%(lineno)s %(funcName)s()] -> %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\n",
    "            Config.root_dir + \"/exp/log/\" + tool_funcs.log_file_name(), mode=\"w\"\n",
    "        ),\n",
    "        logging.StreamHandler(),\n",
    "    ],\n",
    ")\n",
    "\n",
    "logging.info(\"python \" + \" \".join(sys.argv))\n",
    "logging.info(\"=================================\")\n",
    "logging.info(Config.to_str())\n",
    "logging.info(\"=================================\")\n",
    "\n",
    "if Config.method in [\"fcl\", \"fedavg\"]:\n",
    "    from fedtraj.model.trainer import FedTrajCLTrainer\n",
    "\n",
    "    trainer_class = FedTrajCLTrainer\n",
    "else:\n",
    "    from fedtraj.model.trainer import TrajCLTrainer\n",
    "\n",
    "    trainer_class = TrajCLTrainer\n",
    "\n",
    "if Config.method == \"fcl\":\n",
    "    from fedtraj.model.trajcl import TrajCL_with_Buffer as TrajCL\n",
    "else:\n",
    "    from fedtraj.model.trajcl import TrajCL\n",
    "\n",
    "trajcl = trainer_class(Config.trajcl_aug1, Config.trajcl_aug2, model_class=TrajCL)\n",
    "# trajcl.load_checkpoint()\n",
    "trajcl.train()\n",
    "trajcl.test()\n",
    "# lcss_test()\n",
    "# trajcl.knn_test('discrete_frechet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from fedtraj.utils.traj import *\n",
    "from fedtraj.model.trainer import TrajCLTrainer\n",
    "\n",
    "trajcl.load_checkpoint()\n",
    "\n",
    "if isinstance(trajcl, TrajCLTrainer):\n",
    "    model = trajcl.model\n",
    "else:\n",
    "    model = trajcl.server.model\n",
    "\n",
    "cellspace = trajcl.cellspace\n",
    "cellspace_emb = trajcl.embs\n",
    "\n",
    "\n",
    "def get_embedding(single_traj):\n",
    "    return batch_get_embedding([single_traj])\n",
    "\n",
    "\n",
    "def batch_get_embedding(batch_traj):\n",
    "    # 将 single_traj 封装为列表并直接计算 trajs2_cell 和 trajs2_p\n",
    "    trajs2_cell, trajs2_p = zip(*[merc2cell2(t, cellspace) for t in batch_traj])\n",
    "\n",
    "    # 生成并填充 trajs2_emb_p\n",
    "    trajs2_emb_p = pad_sequence(\n",
    "        [torch.tensor(generate_spatial_features(t, cellspace)) for t in trajs2_p],\n",
    "        batch_first=False,\n",
    "    ).to(Config.device)\n",
    "\n",
    "    # 生成并填充 trajs2_emb_cell\n",
    "    trajs2_emb_cell = pad_sequence(\n",
    "        [cellspace_emb[list(t)] for t in trajs2_cell], batch_first=False\n",
    "    ).to(Config.device)\n",
    "\n",
    "    # 计算 trajs2_len\n",
    "    trajs2_len = torch.tensor(\n",
    "        [len(t) for t in trajs2_cell], dtype=torch.long, device=Config.device\n",
    "    )\n",
    "\n",
    "    # print(single_traj, trajs2_cell, trajs2_p, trajs2_len)\n",
    "\n",
    "    # 调用模型进行解释并返回结果\n",
    "    return model.interpret(trajs2_emb_cell, trajs2_emb_p, trajs2_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fedtraj.utils.tool_funcs import lonlat2meters\n",
    "\n",
    "\n",
    "def convert_lonlat_traj(trajectory):\n",
    "    merc_traj = [lonlat2meters(point[0], point[1]) for point in trajectory]\n",
    "    return merc_traj\n",
    "\n",
    "\n",
    "test_traj = [\n",
    "    (-8.574678, 41.151951),\n",
    "    (-8.574705, 41.151942),\n",
    "    (-8.574696, 41.151933),\n",
    "    (-8.574723, 41.151933),\n",
    "    (-8.574714, 41.151924),\n",
    "    (-8.574714, 41.151924),\n",
    "    (-8.575164, 41.150934),\n",
    "    (-8.577135, 41.150232),\n",
    "    (-8.57853, 41.148639),\n",
    "    (-8.579745, 41.147316),\n",
    "]\n",
    "\n",
    "get_embedding(convert_lonlat_traj(test_traj)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from easydict import Easydict\n",
    "\n",
    "\n",
    "class Segment(EasyDict):\n",
    "    def __init__(self, segment_id, points, emb):\n",
    "        super().__init__()\n",
    "        self.id = segment_id\n",
    "        self.points = points\n",
    "        self.emb = emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[utils.py:125 get_federated_segments()] -> [Split dataset and convert to segments] start converting\n",
      "0it [00:00, ?it/s]d:\\codes\\TrajMM\\fedtraj\\utils\\trajclus.py:19: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  projection = line[0] + (dot_product / line_length_squared) * line_vector\n",
      "163it [00:00, 514.92it/s]\n",
      "164it [00:00, 530.72it/s]\n",
      "164it [00:01, 157.73it/s]\n",
      "164it [00:00, 217.33it/s]\n",
      "164it [00:15, 10.72it/s]\n",
      "[utils.py:128 get_federated_segments()] -> [Split dataset and convert to segments] done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from fedtraj.utils.data_loader import TrajDataset\n",
    "from fedtraj.model.trainer.utils import *\n",
    "from tqdm import tqdm\n",
    "\n",
    "trajs = pd.read_pickle(Config.dataset_file)\n",
    "traj_dataset = get_federated_segments(TrajDataset(trajs), fed_num=Config.cls_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_pickle(df, file_path, batch_size=16):\n",
    "    selected_df = df\n",
    "    merc_seqs = selected_df[\"merc_seq\"].tolist()\n",
    "    embs = []\n",
    "    # 按批量大小处理数据\n",
    "    num_batches = len(merc_seqs) // batch_size + (1 if len(merc_seqs) % batch_size != 0 else 0)\n",
    "    for i in tqdm(range(num_batches)):\n",
    "        start_idx = i * batch_size\n",
    "        end_idx = min((i + 1) * batch_size, len(merc_seqs))\n",
    "        batch_merc_seqs = merc_seqs[start_idx:end_idx]\n",
    "        # 批量获取嵌入向量\n",
    "        batch_embs = batch_get_embedding(batch_merc_seqs)\n",
    "        embs.append(batch_embs)\n",
    "    # 拼接所有批次的嵌入向量\n",
    "    embs = torch.cat(embs, dim=0)\n",
    "    # 保存嵌入向量到文件\n",
    "    torch.save(embs, os.path.join(file_path, \"embs.pt\"))\n",
    "    # 保存数据框到 pickle 文件\n",
    "    selected_df.to_pickle(os.path.join(file_path, \"segments.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/131 [00:00<?, ?it/s]d:\\installation\\conda\\envs\\py310\\lib\\site-packages\\torch\\nn\\functional.py:5849: UserWarning: Support for mismatched src_key_padding_mask and mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "100%|██████████| 131/131 [00:18<00:00,  7.15it/s]\n",
      "100%|██████████| 126/126 [00:17<00:00,  7.40it/s]\n",
      "100%|██████████| 138/138 [00:22<00:00,  6.13it/s]\n",
      "100%|██████████| 150/150 [00:23<00:00,  6.31it/s]\n",
      "100%|██████████| 169/169 [00:25<00:00,  6.60it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, dataset in enumerate(traj_dataset):\n",
    "    save_path = os.path.join(r\"D:\\codes\\TrajMM\\resource\\results\\test\", f\"fed_{i+1}\")\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    save_to_pickle(\n",
    "        dataset.data, save_path, batch_size=16\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, dataset in enumerate(traj_dataset):\n",
    "    save_path = os.path.join(r\"D:\\codes\\TrajMM\\resource\\results\\test\", f\"fed_{i+1}\")\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    save_to_pickle(\n",
    "        dataset.data, save_path, batch_size=16\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "import random\n",
    "from typing import List, Dict, Callable\n",
    "from collections import defaultdict\n",
    "from easydict import EasyDict\n",
    "import math\n",
    "import torch\n",
    "from math import atan2, sin\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class Segment(EasyDict):\n",
    "    def __init__(self, segment_id, points, emb):\n",
    "        super().__init__()\n",
    "        self.id = segment_id\n",
    "        self.points = points\n",
    "        self.emb = emb\n",
    "        self.neighbor_count = 0\n",
    "        self.local_neighbor = []\n",
    "\n",
    "\n",
    "class Cluster:\n",
    "    def __init__(self, segments):\n",
    "        self.items = segments\n",
    "        self.size = len(segments)\n",
    "        self.centroid = self._calculate_centroid()\n",
    "        self.radius = self._calculate_radius()\n",
    "        self.merged = False\n",
    "\n",
    "    def _get_segment_midpoint(self, seg):\n",
    "        start, end = seg.points[0], seg.points[-1]\n",
    "        mid_x = (start[0] + end[0]) / 2\n",
    "        mid_y = (start[1] + end[1]) / 2\n",
    "        return (mid_x, mid_y)\n",
    "\n",
    "    def _calculate_centroid(self):\n",
    "        total_x = 0\n",
    "        total_y = 0\n",
    "        for seg in self.items:\n",
    "            mid_x, mid_y = self._get_segment_midpoint(seg)\n",
    "            total_x += mid_x\n",
    "            total_y += mid_y\n",
    "        centroid_x = total_x / self.size\n",
    "        centroid_y = total_y / self.size\n",
    "        return (centroid_x, centroid_y)\n",
    "\n",
    "    def _calculate_radius(self):\n",
    "        max_distance = 0\n",
    "        for seg in self.items:\n",
    "            midpoint = self._get_segment_midpoint(seg)\n",
    "            distance = self.compute_point_distance(midpoint, self.centroid)\n",
    "            if distance > max_distance:\n",
    "                max_distance = distance\n",
    "        return max_distance\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_point_distance(p1, p2):\n",
    "        return math.sqrt((p1[0] - p2[0]) ** 2 + (p1[1] - p2[1]) ** 2)\n",
    "\n",
    "\n",
    "def compute_angular_distance(seg1, seg2):\n",
    "    start1, end1 = seg1.points[0], seg1.points[-1]\n",
    "    start2, end2 = seg2.points[0], seg2.points[-1]\n",
    "    vector1 = (end1[0] - start1[0], end1[1] - start1[1])\n",
    "    vector2 = (end2[0] - start2[0], end2[1] - start2[1])\n",
    "    angle1 = atan2(vector1[1], vector1[0])\n",
    "    angle2 = atan2(vector2[1], vector2[0])\n",
    "    angle_diff = abs(angle1 - angle2)\n",
    "    if angle_diff > np.pi:\n",
    "        angle_diff = 2 * np.pi - angle_diff\n",
    "    len1 = Cluster.compute_point_distance(start1, end1)\n",
    "    len2 = Cluster.compute_point_distance(start2, end2)\n",
    "    return abs(sin(angle_diff)) * max(len1, len2)\n",
    "\n",
    "\n",
    "def compute_vector_distance(r1, r2):\n",
    "    r1 = torch.tensor(r1) if not isinstance(r1, torch.Tensor) else r1\n",
    "    r2 = torch.tensor(r2) if not isinstance(r2, torch.Tensor) else r2\n",
    "    sum_square = torch.sum((r1 - r2) ** 2)\n",
    "    return torch.sqrt(sum_square).item()\n",
    "\n",
    "\n",
    "def calculate_distance(seg1, seg2, alpha, beta, gamma):\n",
    "    d1 = Cluster.compute_point_distance(\n",
    "        seg1.points[0], seg2.points[0]\n",
    "    ) + Cluster.compute_point_distance(seg1.points[-1], seg2.points[-1])\n",
    "    # d2 = compute_angular_distance(seg1, seg2)\n",
    "    d3 = compute_vector_distance(seg1.emb, seg2.emb)\n",
    "    return alpha * d1 + gamma * d3\n",
    "\n",
    "\n",
    "def dbscan(\n",
    "    trajs: List[Segment], eps: float, min_pts: int, distance_func: Callable\n",
    ") -> Dict:\n",
    "    if not trajs:\n",
    "        return {}\n",
    "\n",
    "    # 创建 tqdm 进度条\n",
    "    num_segments = len(trajs)\n",
    "    total_iterations = num_segments * (num_segments - 1) // 2\n",
    "    progress_bar = tqdm(total=total_iterations, desc=\"计算距离矩阵\")\n",
    "    count = 0\n",
    "    distance_matrix = np.zeros((num_segments, num_segments))\n",
    "    for i in range(num_segments):\n",
    "        for j in range(i + 1, num_segments):\n",
    "            dist = distance_func(trajs[i], trajs[j])\n",
    "            distance_matrix[i, j] = dist\n",
    "            distance_matrix[j, i] = dist\n",
    "            # 更新进度条\n",
    "            count += 1\n",
    "            progress_bar.update(1)\n",
    "\n",
    "    db = DBSCAN(eps=eps, min_samples=min_pts, metric=\"precomputed\")\n",
    "    labels = db.fit_predict(distance_matrix)\n",
    "\n",
    "    result = {}\n",
    "    for seg in trajs:\n",
    "        seg.neighbor_count = 0\n",
    "        seg.local_neighbor = []\n",
    "\n",
    "    # 根据距离确定邻居点\n",
    "    for i, seg in enumerate(trajs):\n",
    "        # 只考虑 j > i 的情况，避免重复计算\n",
    "        for j in range(i + 1, len(trajs)):\n",
    "            other_seg = trajs[j]\n",
    "            if distance_func(seg, other_seg) < eps:\n",
    "                # 两个线段互为邻居，分别增加邻居计数\n",
    "                seg.neighbor_count += 1\n",
    "                other_seg.neighbor_count += 1\n",
    "                # 分别将对方添加到自己的邻居列表中\n",
    "                seg.local_neighbor.append(other_seg)\n",
    "                other_seg.local_neighbor.append(seg)\n",
    "\n",
    "    for seg, label in zip(trajs, labels):\n",
    "        result[seg.id] = (seg.neighbor_count, label)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def random_select_traj(lres_i: Dict, min_pts: int, num: int) -> List:\n",
    "    candidates = [\n",
    "        seg_id for seg_id, (count, _) in lres_i.items() if count >= min_pts - 1\n",
    "    ]\n",
    "    return random.sample(candidates, min(num, len(candidates))) if candidates else []\n",
    "\n",
    "\n",
    "def update(\n",
    "    traj: Segment,\n",
    "    c: int,\n",
    "    lres: Dict,\n",
    "    all_local_segments: List[Segment],\n",
    "    min_pts: int,\n",
    "    eps: float,\n",
    "    distance_func: Callable,\n",
    "    updated_segments: set = None,\n",
    "):\n",
    "    if updated_segments is None:\n",
    "        updated_segments = set()\n",
    "    if traj.id in updated_segments:\n",
    "        return\n",
    "    updated_segments.add(traj.id)\n",
    "\n",
    "    # 更新轨迹段所属簇编号\n",
    "    lres[traj.id] = (lres[traj.id][0], c)\n",
    "\n",
    "    # 更新簇内其他成员\n",
    "    if lres[traj.id][1] is not None:\n",
    "        same_cluster_segs = [\n",
    "            seg_id for seg_id, (_, label) in lres.items() if label == lres[traj.id][1]\n",
    "        ]\n",
    "        for seg_id in same_cluster_segs:\n",
    "            lres[seg_id] = (lres[seg_id][0], c)\n",
    "\n",
    "    # 使用本地邻居信息进行加速\n",
    "    for other_seg in traj.local_neighbor:\n",
    "        if other_seg.neighbor_count >= min_pts:\n",
    "            update(\n",
    "                other_seg,\n",
    "                c,\n",
    "                lres,\n",
    "                all_local_segments,\n",
    "                min_pts,\n",
    "                eps,\n",
    "                distance_func,\n",
    "                updated_segments,\n",
    "            )\n",
    "\n",
    "\n",
    "def federated_clustering(\n",
    "    fed_trajs: List[List[Segment]],\n",
    "    eps: float,\n",
    "    min_pts: int,\n",
    "    k: int,\n",
    "    num: int,\n",
    "    alpha: float,\n",
    "    beta: float,\n",
    "    gamma: float,\n",
    ") -> List[Cluster]:\n",
    "    from functools import partial\n",
    "\n",
    "    distance_func = partial(calculate_distance, alpha=alpha, beta=beta, gamma=gamma)\n",
    "    local_results = [\n",
    "        dbscan(trajs, eps, min_pts, distance_func=distance_func) for trajs in fed_trajs\n",
    "    ]\n",
    "\n",
    "    no_merge_count = 0  # 初始化连续未合并的轮数为 0\n",
    "\n",
    "    while no_merge_count < k:  # 当连续未合并的轮数小于 k 时继续迭代\n",
    "        merged = False\n",
    "        selected_segments = []\n",
    "        for lres in local_results:\n",
    "            if lres:\n",
    "                selected_segments.append(random_select_traj(lres, min_pts, num))\n",
    "            else:\n",
    "                selected_segments.append([])\n",
    "\n",
    "        merged_index = []\n",
    "        for i in range(len(fed_trajs)):\n",
    "            for j in range(i + 1, len(fed_trajs)):\n",
    "                for p in range(len(selected_segments[i])):\n",
    "                    for q in range(len(selected_segments[j])):\n",
    "                        seg_i_id, seg_j_id = (\n",
    "                            selected_segments[i][p],\n",
    "                            selected_segments[j][q],\n",
    "                        )\n",
    "                        try:\n",
    "                            seg_i = next(\n",
    "                                seg for seg in fed_trajs[i] if seg.id == seg_i_id\n",
    "                            )\n",
    "                            seg_j = next(\n",
    "                                seg for seg in fed_trajs[j] if seg.id == seg_j_id\n",
    "                            )\n",
    "                        except StopIteration:\n",
    "                            print(f\"no such id {i, j}\")\n",
    "                            continue\n",
    "                        # 获取两个轨迹段的簇标签，跳过已经同簇了的轨迹段\n",
    "                        label_i = local_results[i][seg_i_id][1]\n",
    "                        label_j = local_results[j][seg_j_id][1]\n",
    "                        if label_i == label_j:\n",
    "                            continue\n",
    "\n",
    "                        distance = distance_func(seg_i, seg_j)\n",
    "\n",
    "                        # 判断簇标签不同且距离小于阈值\n",
    "                        if distance < eps:\n",
    "                            # 更新邻居数\n",
    "                            seg_i.neighbor_count += 1\n",
    "                            seg_j.neighbor_count += 1\n",
    "                            local_results[i][seg_i_id] = (\n",
    "                                seg_i.neighbor_count,\n",
    "                                local_results[i][seg_i_id][1],\n",
    "                            )\n",
    "                            local_results[j][seg_j_id] = (\n",
    "                                seg_j.neighbor_count,\n",
    "                                local_results[j][seg_j_id][1],\n",
    "                            )\n",
    "\n",
    "                            # 根据三角关系更新两个轨迹段各自的本地邻居ntraj\n",
    "                            for ntraj in seg_i.local_neighbor:\n",
    "                                if distance_func(ntraj, seg_j) < eps:\n",
    "                                    ntraj.neighbor_count += 1\n",
    "                                    local_results[i][ntraj.id] = (\n",
    "                                        ntraj.neighbor_count,\n",
    "                                        local_results[i][ntraj.id][1],\n",
    "                                    )\n",
    "\n",
    "                            for ntraj in seg_j.local_neighbor:\n",
    "                                if distance_func(ntraj, seg_i) < eps:\n",
    "                                    ntraj.neighbor_count += 1\n",
    "                                    local_results[j][ntraj.id] = (\n",
    "                                        ntraj.neighbor_count,\n",
    "                                        local_results[j][ntraj.id][1],\n",
    "                                    )\n",
    "\n",
    "                            # 递归更新各自的本地邻居的聚类标签\n",
    "                            new_cluster_id = (\n",
    "                                local_results[i][seg_i_id][1]\n",
    "                                if local_results[i][seg_i_id][1] != -1\n",
    "                                else local_results[j][seg_j_id][1]\n",
    "                            )\n",
    "                            update(\n",
    "                                seg_i,\n",
    "                                new_cluster_id,\n",
    "                                local_results[i],\n",
    "                                fed_trajs[i],\n",
    "                                min_pts,\n",
    "                                eps,\n",
    "                                distance_func,\n",
    "                            )\n",
    "                            update(\n",
    "                                seg_j,\n",
    "                                new_cluster_id,\n",
    "                                local_results[j],\n",
    "                                fed_trajs[j],\n",
    "                                min_pts,\n",
    "                                eps,\n",
    "                                distance_func,\n",
    "                            )\n",
    "                            merged = True\n",
    "                            merged_index.append(((i, p), (j, p)))\n",
    "        if merged:\n",
    "            no_merge_count = 0  # 发生合并，重置计数器\n",
    "        else:\n",
    "            no_merge_count += 1  # 未发生合并，计数器加 1\n",
    "        print(no_merge_count, merged_index)\n",
    "\n",
    "    cluster_mapping = defaultdict(list)\n",
    "    for i, lres in enumerate(local_results):\n",
    "        for seg_id, (_, cluster_id) in lres.items():\n",
    "            if cluster_id != -1:\n",
    "                try:\n",
    "                    seg = next(seg for seg in fed_trajs[i] if seg.id == seg_id)\n",
    "                    cluster_mapping[cluster_id].append(seg)\n",
    "                except StopIteration:\n",
    "                    continue\n",
    "\n",
    "    return [Cluster(segs) for segs in cluster_mapping.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "计算距离矩阵:   0%|          | 0/4950 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "计算距离矩阵: 100%|██████████| 4950/4950 [00:00<00:00, 22380.57it/s]\n",
      "计算距离矩阵: 100%|██████████| 4950/4950 [00:00<00:00, 22761.99it/s]\n",
      "计算距离矩阵: 100%|██████████| 4950/4950 [00:00<00:00, 23090.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 []\n",
      "2 []\n",
      "3 []\n",
      "4 []\n",
      "5 []\n",
      "Cluster 0:\n",
      "  Size: 300\n",
      "  Centroid: (0.4878262172993846, 0.4866084334946415)\n",
      "  Radius: 0.589437510464947\n",
      "  Segment IDs: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 生成模拟数据\n",
    "def generate_synthetic_data(num_clients, num_segments_per_client, embedding_dim):\n",
    "    fed_trajs = []\n",
    "    segment_id_counter = 0\n",
    "    for client in range(num_clients):\n",
    "        client_trajs = []\n",
    "        for _ in range(num_segments_per_client):\n",
    "            # 随机生成轨迹段的起点和终点\n",
    "            start_point = (random.random(), random.random())\n",
    "            end_point = (random.random(), random.random())\n",
    "            points = [start_point, end_point]\n",
    "            # 随机生成嵌入向量\n",
    "            emb = torch.tensor([random.random() for _ in range(embedding_dim)])\n",
    "            segment = Segment(segment_id_counter, points, emb)\n",
    "            client_trajs.append(segment)\n",
    "            segment_id_counter += 1\n",
    "        fed_trajs.append(client_trajs)\n",
    "    return fed_trajs\n",
    "\n",
    "\n",
    "# 设置参数\n",
    "num_clients = 3\n",
    "num_segments_per_client = 100\n",
    "embedding_dim = 5\n",
    "eps = 1.0\n",
    "min_pts = 2\n",
    "k = 5\n",
    "num = 3\n",
    "alpha = 0.5\n",
    "beta = 0.\n",
    "gamma = 0.5\n",
    "\n",
    "# 生成模拟数据\n",
    "fed_trajs = generate_synthetic_data(num_clients, num_segments_per_client, embedding_dim)\n",
    "\n",
    "# 进行联邦聚类\n",
    "clusters = federated_clustering(fed_trajs, eps, min_pts, k, num, alpha, beta, gamma)\n",
    "\n",
    "# 打印聚类结果\n",
    "for i, cluster in enumerate(clusters):\n",
    "    print(f\"Cluster {i}:\")\n",
    "    print(f\"  Size: {cluster.size}\")\n",
    "    print(f\"  Centroid: {cluster.centroid}\")\n",
    "    print(f\"  Radius: {cluster.radius}\")\n",
    "    print(\"  Segment IDs:\", [seg.id for seg in cluster.items])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
